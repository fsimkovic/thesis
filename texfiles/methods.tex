\section{Selection of datasets}
\subsection{ORIGINAL dataset} \label{sec:methods_dataset_original}
A test set of 21 globular protein targets was manually selected to include a range of chain lengths, fold architectures, X-ray diffraction data resolutions and \gls{msa} depths for contact prediction  (\cref{table:appendix_dataset_original}). The targets were chosen to include the three main fold classes: all-\textalpha, all-\textbeta, and mixed \textalpha-\textbeta\ (\textalpha/\textbeta\ and \textalpha+\textbeta). The target chain lengths cover a range from 62 to 221 residues. Each crystal structure contains a single molecule per asymmetric unit and the resolution of the experimental data is in range of 1.0 to 2.3\AA.

\subsection{PREDICTORS dataset} \label{sec:methods_dataset_predictors}
An unbiased selection of 27 non-redundant protein targets was selected using the following protocol. For target-specific details, please refer to \cref{table:appendix_dataset_predictors}.

The PFAM v29.0 \cite{Finn2016-zo} database was filtered for all protein families with at least one representative structure in the RCSB \gls{pdb} \cite{Berman2000-ua} database. Each representative had to have monomeric protein stoichiometry and its fold classified in the SCOPe v2.05 database \cite{Chandonia2017-vf}. Targets with fold assignments other than "a" (all-\textalpha), "b" (all-\textbeta), "c" (mixed \textalpha+\textbeta) or "d" (mixed \textalpha/\textbeta) were excluded to focus on regular globular protein folds. Each resulting protein target was screened against the RESTful API of the RCSB \gls{pdb} (\url{www.rcsb.org}) webserver to identify targets meeting the following criteria: experimental technique is X-ray crystallography; chain length is $\geq100$ residues and $\leq250$ residues; resolution is between 1.3 and 2.3\AA; structure factor amplitudes are deposited in the \gls{pdb} \cite{Berman2000-ua} database; and there is only a single molecule in the asymmetric unit. The resulting protein structures were cross-validated against the \gls{pdbtm} \cite{Tusnady2005-ns} to exclude any possible matches. Subsequently, one representative entry was randomly selected for each PFAM family.

All PFAM family representatives obtained in the previous step were grouped by domain fold, target chain length and PFAM alignment depth (see \cref{eq:methods_meff}). Each target was sorted in one of three fold bins depending on their SCOPe fold assignment: all-\textalpha, all-\textbeta, and mixed \textalpha-\textbeta\ (\textalpha+\textbeta\ and \textalpha/\textbeta). Each target was further binned by chain length (derived from the deposited sequence in the RCSB \gls{pdb}) into three different bins: $[100, 150)$, $[150, 200)$, and $[200, 250]$. Lastly, each fold bin was also sub-grouped by alignment depth, which was calculated for the sequence alignments of each PFAM family. Three bins were established: $[0, 100)$, $[100, 200)$, and $[200, \infty]$. Thus, all targets were grouped by fold class and further grouped by chain length or alignment depth.

In the final step, random targets were selected from each bin to obtain nine targets per fold sampling a spectrum of target chain lengths and alignment depths. To ensure similar samples across the fold classes, random PFAM entries were continuously picked from the fold bins until the mean target chain length and alignment depth of nine representatives of each fold class were within $\pm15$ of each other. This resulted in 27 targets in the final set.

\subsection{TRANSMEMBRANE dataset} \label{sec:methods_dataset_transmembrane}
The selection of this dataset was done by \textcite{Thomas2017-sh}. In summary, 14 non-redundant transmembrane protein targets were selected from the \gls{pdbtm} \cite{Tusnady2005-ns}, with a chain length of $<250$ residues and resolution of $<2.5$\AA. The final selection is summarised in \cref{table:appendix_dataset_transmembrane}.

\section{Enhancement of \textbeta-sheet restraints} \label{sec:methods_bbcontacts_addition}
Structure prediction of \textbeta-strand containing protein targets \textit{ab initio} is a notoriously challenging task. \textbeta-strands, potentially far in sequence space, form a \textbeta-sheet in 3-dimensions. Since fragment-assembly algorithms work on the basis of randomly inserting one fragment at the time, the probability of \textbeta-sheet formation is much lower compared to \textalpha-helices. 

Recent advances in \textit{ab initio} structure prediction have seen great improvements in structure prediction quality through the use of predicted residue-residue contacts as distance restraints (see \cref{sec:introduction_contact_prediction}). However, only a single paper has specifically focused on improvements to the structure prediction of \textbeta-sheet formation \cite{Hayat2015-ut}. To enhance the probability of \textbeta-sheet formation in \textit{ab initio} structure prediction, part of this thesis focused on a more general model to enrich restraints between \textbeta-strands to attempt better super-secondary quality in the final decoys.

A more general approach, compared to \textcite{Hayat2015-ut}, which focused exclusively on \textbeta-barrel proteins, was developed combining a starting set of contact pairs with a specifically-prepared set obtained from BBCONTACTS \cite{Andreani2015-qn}. A HHBLITS \cite{Remmert2011-kt} \gls{msa} was constructed using two sequence-search iterations with an E-value cutoff of $10^{-3}$ against the \texttt{uniprot20} database \cite{Bateman2017-pb}. Redundant sequences were removed from the \gls{msa} to 90\% sequence identity using HHFILTER \cite{Remmert2011-kt}. Subsequently, the \gls{msa} was subjected to CCMPRED \cite{Seemayer2014-zp} for co-evolution based contact prediction, which was chosen to reproduce the approach published by \textcite{Andreani2015-qn}. Alternative starting predictions might be provided although such approach was not tested within the scope of this work. Additionally to the contact prediction, the BBCONTACTS algorithms requires a secondary-structure prediction, which can be obtained using the \texttt{addss.pl} script \cite{Remmert2011-kt} distributed with the HHSUITE \cite{Soding2005-hw}. BBCONTACTS also requires a descriptor for the diversity of the original \gls{msa} \cite{Andreani2015-qn}, which is calculated using \cref{eq:methods_alndiversity}. Ultimately, the BBCONTACTS algorithm yields \textbeta-strand-specific contact predictions identified from the starting set of contacts.

The BBCONTACTS contact pairs were added to a base set of contact pairs usually obtained from a separate (meta-)predictor. The first step included the filtering of the BBCONTACTS contact list to exclude any one- or two-strand pairings, i.e. sequences of contacts with less than three consecutive contacts, because those contact pairs are typically \gls{fp} ones (Jessica Andreani, personal communication). The subsequent combination of the two sets of contact pairs was done by simple union of the lists; however, if a contact pair was in the intersection, a contact-pair related weight was doubled to allow subsequent modifications of the energy term in distance restraint creation. Furthermore, additional contact pairs were inferred if not present in the base set of contact pairs. The inference worked on the basis that any neighbouring contacts (i.e. $i,j\pm1$; $i,j\pm2$; $i\pm  1,j$; $i\pm2,j$) to contact $i,j$ must be present, and thus any missing such contacts were automatically added to the final set of contact pairs. 

\section{Evaluation of data}
This section defines and describes data validation and verification procedures and equations used throughout one or more studies presented in this thesis. These definitions serve as a reference and define naming conventions where appropriate. All of the sequence- and contact-related analysis routines are implemented in CONKIT \cite{Simkovic2017-us}.

\subsection{Sequence alignment data}
\subsubsection{Sequence alignment diversity}
The sequence diversity in a \gls{msa} can be described by the number of sequences ($M$) it contains divided by the sequence length of the target ($L$). The diversity metric is used in BBCONTACTS as input parameter \cite{Andreani2015-qn}. The \gls{msa} diversity \texteta is defined in \cref{eq:methods_alndiversity}.

\begin{equation}
    \eta=\frac{M}{L}
    \label{eq:methods_alndiversity}
\end{equation}
\equations{Sequence Alignment diversity}

\subsubsection{Sequence alignment depth}
Co-evolution based residue-residue contact prediction is dependent on an input \gls{msa} ideally containing all homologous sequences found in the queried database. However, the \gls{msa} needs a certain level of sequence diversity amongst the homologs to accurately capture the co-evolution signal. The alignment depth --- often also referred to as \gls{meff} --- captures this diversity by computing the number of non-redundant sequences in the \gls{msa}.

\begin{equation}
    M_{eff}=\sum_{i}\frac{1}{\sum_{j}S_{i,j}}
    \label{eq:methods_meff}
\end{equation}
\equations{Sequence Alignment depth}

Various approaches exist for computing \gls{meff} \cite{Morcos2011-lk,Jones2012-ks,Jones2015-vq} yielding similar results \cite{Skwark2014-qp}. In this thesis, the approach defined by \textcite{Morcos2011-lk} is used. \textcite{Morcos2011-lk} first described the approach by which sequence weights are computed by means of Hamming distances between all possible sequence combinations in the \gls{msa} (\cref{eq:methods_meff}). All Hamming distances are then classed as determinant ($S_{i,j}=1$) or not ($S_{i,j}=0$) if their sequence-count-normalised value is more than a predefined identity threshold, which was set to 80\% in this work. Subsequently, the contribution of each sequence to the overall alignment depth is defined as the reciprocal of its sum of determinant sequences ($\Sigma_{j} S_{i,j}$). The sum of all those contributions ultimately defines the alignment depth.

It is worth pointing out that $M_{eff}$ and $N_{eff}$ are both commonly used in literature to describe the alignment depth. Although the calculation might differ between cases --- i.e. clustering-based or Hamming-distance-based --- both refer to the same concept.

\subsection{Contact prediction data}
\subsubsection{Contact map coverage}
In the interpretation of a truncated contact map it is often of interest to identify the sequence coverage by the final set of contact pairs. In this particular context, coverage is defined by the number of residues ($N_{map}$) for which at least one contact pair exists proportional to the total number of residues in the target chain ($L$). Thus, the contact map coverage can be defined by \cref{eq:methods_contact_coverage}.

\begin{equation}
    Coverage=\frac{N_{map}}{L}
    \label{eq:methods_contact_coverage}
\end{equation}
\equations{Contact map coverage}

\subsubsection{Contact map precision} \label{sec:methods_contact_map_prec} 
The precision of a set of contact pairs is equivalent to the proportion of \gls{tp} contact pairs compared to the number of \gls{tp} and \gls{fp} ones (\cref{eq:methods_contact_precision}). A contact pair was considered a \gls{tp} if the equivalent C\textbeta\ (C\textalpha\ for glycine) atoms in the native structure were $<8$\AA\ apart, otherwise a \gls{fp}. The precision value ranges from 0 to 1 with a value of 1 indicating all contact pairs are \gls{tp}s. 

\begin{equation} 
    Precision=\frac{TP}{TP-FP}
    \label{eq:methods_contact_precision}
\end{equation}
\equations{Precision score}

If contacts were unmatched between the target sequence and reference structure, they were not taken into account in the calculation of the precision score. This might affect a precision value; however, it also avoids inference of distances for residues absent in the native structure and therefore potentially incorrect results.

\subsubsection{Range-dependent contact satisfaction} \label{sec:methods_longrange_satisfaction}
The range-dependent contact pair satisfaction score is computed identically to the precision of sets of contact pairs (\cref{sec:methods_contact_map_prec}). The main difference is that contact pairs are grouped by their sequence separation: short-range with $<12$, medium-range with $<24$ and long-range with $\geq23$ residues.

\subsubsection{Contact map Jaccard index}
The Jaccard index quantifies the similarity between two sets of contact pairs. It describes the proportion of contact pairs in the intersection compared to the union between the two sets (\cref{eq:methods_jaccard_index}) \cite{Wuyun2016-hh}.

\begin{equation}
    J_{x,y}=\frac{\left |x \cap y\right |}{\left |x \cup y\right |}
    \label{eq:methods_jaccard_index}
\end{equation}
\equations{Jaccard index}

The variables $x$ and $y$ are two sets of contact pairs. $\left |x \cap y\right |$ is the number of elements in the intersection of $x$ and $y$, and the $\left |x \cup y\right |$ represents the number of elements in the union of $x$ and $y$. The Jaccard index falls in the range [0,1], with a value of 1 corresponding to identical sets of contact pairs and 0 to non-identical ones. 

It is worth noting that only exact matches are considered and the neighbourhood of a single contact is ignored.
\subsubsection{Contact map singleton content}
Most sets of residue-residue contact pairs contain a fraction of contact pairs that do not co-localise with others. These contact pairs --- referred to as singleton contacts from here onwards --- typically show a high \gls{fp} rate and could be considered noise (although sometimes they encode \gls{tp} contacts in an oligomeric interface) \cite{Skwark2014-qp}. Such contacts are also often the ones to be down-weighted by neural network architectures of metapredictors, such as PCONSC2 \cite{Skwark2014-qp} or METAPSICOV \cite{Jones2015-vq}. To quantify the fraction of singleton contacts, a distance-based clustering routine was defined to isolate singleton contact pairs, and thus describe the level of noise in the prediction.

To identify singleton contact pairs in a set of contacts, the neighbourhood of each pair was searched for the presence of other contacts. The search radius was defined by $\pm2$ residues in a 2D-representation of the contact map. If no other contact pair was identified under such constraint, the contact pair was classified as singleton.

\subsection{Structure prediction data}
\subsubsection{Root-Mean-Square Deviation of atomic positions}
The \gls{rmsd} is a measure to quantify the average atomic distance between two protein structures (\cref{eq:methods_rmsd}). The \gls{rmsd} is sequence-independent, and measures the distance between C\textalpha\ atoms.

\begin{equation}
    RMSD=\sqrt{\frac{1}{n}\sum_{i,j}{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2}}
    \label{eq:methods_rmsd}
\end{equation}
\equations{Root-Mean-Square Deviation}

\subsubsection{Template-Modelling score}
The \gls{tmscore} is an alternative measure of the similarity between two protein structures \cite{Zhang2004-ha}. Unlike the \gls{rmsd}, the \gls{tmscore} score assigns a length-dependent weight to the distances between atoms, with shorter distances getting assigned stronger weights \cite{Zhang2004-ha}. This results in the \gls{tmscore} being less sensitive to local dissimilarities than the \gls{rmsd}, and thus a better metric for overall fold similarity. The \gls{tmscore} has widely been accepted as a standard for assessing the similarity between two structures, particularly in the field of \textit{ab initio} structure prediction.

\begin{equation}
    TMscore=max\left[\frac{1}{L_{target}}\sum_{i}^{L_{aligned}}{\frac{1}{1+\left(\frac{d_i}{d_0}\right)^2}}\right]
    \label{eq:methods_tmscore}
\end{equation}
\equations{Template-Modelling score}

$d_i$ describes the distance between the \textit{ith} pair of residues. The distance scale $d_0$ to normalise the distances is defined by the equation $1.24\sqrt[3]{L_{target}-15}-1.8$. The \gls{tmscore} value falls in the range (0, 1]. A \gls{tmscore} value of $<0.2$ indicates two random unrelated structures, and a value $>0.5$ roughly the same fold \cite{Xu2010-kr}

\subsection{Molecular Replacement data}
\subsubsection{Register-Independent Overlap} \label{sec:methods_rio}
The \gls{rio} score \cite{Thomas2015-wu} is a measure of structural similarity between two protein structures considering the total number of atoms within $<1.5$\AA. The \gls{rio} can be separated into the in- (\gls{rio}\textsubscript{in}) and out-of-register (\gls{rio}\textsubscript{out}) score considering the sequence register between the model and the target. The \gls{rio} score is primarily a measure for post-\gls{mr} search models to assess the placement of search model atoms with respect to the previously solved crystal structure. To avoid the addition of single atoms place correctly purely by chance, the \gls{rio} metric requires at least three consecutive C\textalpha\ atoms to be within the 1.5\AA\ threshold.

\subsubsection{Structure solution} \label{sec:methods_mr_success}
\gls{mr} structure solutions were assessed throughout all works presented in this thesis by the \gls{cc} \cite{Fujinaga1987-vh} and \gls{acl} scores computed by SHELXE. SHELXE performs density modification and main-chain tracing of the refined \gls{mr} solution \cite{Thorn2013-le}. \textcite{Thorn2013-le} highlighted in their work that a \gls{cc} of $\geq25$\% indicates a successful structure solution. Additionally, previous research with AMPLE \cite{Thomas2015-wu} has shown that an \gls{acl} of the trace needs to be $\geq10$ residues.

In most studies in this thesis, additionally to the SHELXE metrics the post-SHELXE auto-built structures needed R values of $\leq0.45$. The R values had to be acquired by at least one of the Buccaneer \cite{Cowtan2006-xv} or ARP/wARP \cite{Cohen2007-wg} solutions.

Lastly, the PHASER \gls{tfz} and \gls{llg} metrics were also considered when automatically judging a \gls{mr} solution. Values of $>8$ and $>120$ were required, respectively. However, the PHASER metrics do not always indicate a structure solution --- particularly for smaller fragments --- and thus was not considered an essential metric to pass to be considered a successful solution.
